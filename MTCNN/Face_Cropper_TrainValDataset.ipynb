{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src import detect_faces, show_bboxes\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../Dataset/emotiw/'\n",
    "face_coordinates_directory = '../Dataset/FaceCoordinates/'\n",
    "processed_dataset_path = '../Dataset/CroppedFaces/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Val Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: '../Dataset/emotiw/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-27b703d6c46d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m image_datasets = {x : datasets.ImageFolder(os.path.join(dataset_path, x))\n\u001b[1;32m----> 2\u001b[1;33m                     for x in ['train', 'val']}\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-27b703d6c46d>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m image_datasets = {x : datasets.ImageFolder(os.path.join(dataset_path, x))\n\u001b[1;32m----> 2\u001b[1;33m                     for x in ['train', 'val']}\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\envs\\pytorch0.4\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[0;32m    176\u001b[0m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS,\n\u001b[0;32m    177\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                                           target_transform=target_transform)\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\envs\\pytorch0.4\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\envs\\pytorch0.4\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(dir)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: '../Dataset/emotiw/train'"
     ]
    }
   ],
   "source": [
    "image_datasets = {x : datasets.ImageFolder(os.path.join(dataset_path, x))\n",
    "                    for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = image_datasets['train']\n",
    "validation_dataset = image_datasets['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_train = sorted(os.listdir(dataset_path + 'train/Negative/'))\n",
    "neu_train = sorted(os.listdir(dataset_path + 'train/Neutral/'))\n",
    "pos_train = sorted(os.listdir(dataset_path + 'train/Positive/'))\n",
    "\n",
    "neg_val = sorted(os.listdir(dataset_path + 'val/Negative/'))\n",
    "neu_val = sorted(os.listdir(dataset_path + 'val/Neutral/'))\n",
    "pos_val = sorted(os.listdir(dataset_path + 'val/Positive/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_train_filelist = [x.split('.')[0] for x in neg_train]\n",
    "neu_train_filelist = [x.split('.')[0] for x in neu_train]\n",
    "pos_train_filelist = [x.split('.')[0] for x in pos_train]\n",
    "\n",
    "neg_val_filelist = [x.split('.')[0] for x in neg_val]\n",
    "neu_val_filelist = [x.split('.')[0] for x in neu_val]\n",
    "pos_val_filelist = [x.split('.')[0] for x in pos_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neg_train_filelist[:10])\n",
    "print(neu_train_filelist[:10])\n",
    "print(pos_train_filelist[:10])\n",
    "\n",
    "print(neg_val_filelist[:10])\n",
    "print(neu_val_filelist[:10])\n",
    "print(pos_val_filelist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filelist = neg_train_filelist + neu_train_filelist + pos_train_filelist\n",
    "val_filelist = neg_val_filelist + neu_val_filelist + pos_val_filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_dataset))\n",
    "print(len(validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_dataset)):\n",
    "    try:\n",
    "        image, label = training_dataset[i]\n",
    "        face_list = []\n",
    "        landmarks_new_coordinates = []\n",
    "        if label == 0:\n",
    "            if os.path.isfile(processed_dataset_path + 'train/Negative/' + train_filelist[i] + '.npz'):\n",
    "                print(train_filelist[i] + ' Already present')\n",
    "                continue\n",
    "\n",
    "            bbox_lm = np.load(face_coordinates_directory + 'train/Negative/' + train_filelist[i] +'.npz')\n",
    "            bounding_boxes = bbox_lm['a']\n",
    "            if bounding_boxes.size == 0 or (bounding_boxes[0] == 0).all():\n",
    "                print(\"No bounding boxes for \" + train_filelist[i] + \". Adding empty file for the same\")\n",
    "                np.savez(processed_dataset_path + 'train/Negative/' + train_filelist[i], a = np.zeros(1), b = np.zeros(1))\n",
    "                continue\n",
    "            landmarks = bbox_lm['b']\n",
    "\n",
    "            for j in range(len(bounding_boxes)):\n",
    "                bbox_coordinates = bounding_boxes[j]\n",
    "                landmark = landmarks[j]\n",
    "                img_face = image.crop((bbox_coordinates[0], bbox_coordinates[1], bbox_coordinates[2], bbox_coordinates[3]))\n",
    "\n",
    "                x = bbox_coordinates[0]\n",
    "                y = bbox_coordinates[1]\n",
    "                \n",
    "                for k in range(5):\n",
    "                    landmark[k] -= x\n",
    "                    landmark[k+5] -= y\n",
    "                img_face = np.array(img_face)\n",
    "                landmark = np.array(landmark)\n",
    "\n",
    "\n",
    "                if len(face_list) != 0:\n",
    "                    if img_face.shape[0] == face_list[-1].shape[0]:\n",
    "                        img_face = image.crop((bbox_coordinates[0] - 1, bbox_coordinates[1] - 1, bbox_coordinates[2], bbox_coordinates[3]))\n",
    "                        img_face = np.array(img_face)\n",
    "                        landmark +=1\n",
    "\n",
    "                face_list.append(img_face)\n",
    "                landmarks_new_coordinates.append(landmark)\n",
    "            face_list = np.asarray(face_list)\n",
    "            landmarks_new_coordinates = np.asarray(landmarks_new_coordinates)\n",
    "            np.savez(processed_dataset_path + 'train/Negative/' + train_filelist[i], a = face_list, b = landmarks_new_coordinates)\n",
    "\n",
    "        elif label == 1:\n",
    "\n",
    "            if os.path.isfile(processed_dataset_path + 'train/Neutral/' + train_filelist[i] + '.npz'):\n",
    "                print(train_filelist[i] + ' Already present')\n",
    "                continue\n",
    "\n",
    "            bbox_lm = np.load(face_coordinates_directory + 'train/Neutral/' + train_filelist[i] +'.npz')\n",
    "            bounding_boxes = bbox_lm['a']\n",
    "            if bounding_boxes.size == 0 or (bounding_boxes[0] == 0).all():\n",
    "                print(\"No bounding boxes for \" + train_filelist[i] + \". Adding empty file for the same\")\n",
    "                np.savez(processed_dataset_path + 'train/Neutral/' + train_filelist[i], a = np.zeros(1), b = np.zeros(1))\n",
    "                continue\n",
    "            landmarks = bbox_lm['b']\n",
    "\n",
    "            for j in range(len(bounding_boxes)):\n",
    "                bbox_coordinates = bounding_boxes[j]\n",
    "                landmark = landmarks[j]\n",
    "                img_face = image.crop((bbox_coordinates[0], bbox_coordinates[1], bbox_coordinates[2], bbox_coordinates[3]))\n",
    "   \n",
    "                x = bbox_coordinates[0]\n",
    "                y = bbox_coordinates[1]\n",
    "        \n",
    "                for k in range(5):\n",
    "                    landmark[k] -= x\n",
    "                    landmark[k+5] -= y\n",
    "                img_face = np.array(img_face)\n",
    "                landmark = np.array(landmark)\n",
    "\n",
    "                if len(face_list) != 0:\n",
    "                    if img_face.shape[0] == face_list[-1].shape[0]:\n",
    "                        img_face = image.crop((bbox_coordinates[0] - 1, bbox_coordinates[1] - 1, bbox_coordinates[2], bbox_coordinates[3]))\n",
    "                        img_face = np.array(img_face)\n",
    "                        landmark += 1\n",
    "\n",
    "                face_list.append(img_face)\n",
    "                landmarks_new_coordinates.append(landmark)\n",
    "            face_list = np.asarray(face_list)\n",
    "            landmarks_new_coordinates = np.asarray(landmarks_new_coordinates)\n",
    "            np.savez(processed_dataset_path + 'train/Neutral/' + train_filelist[i], a = face_list, b = landmarks_new_coordinates)\n",
    "\n",
    "        else:\n",
    "            if os.path.isfile(processed_dataset_path + 'train/Positive/' + train_filelist[i] + '.npz'):\n",
    "                print(train_filelist[i] + ' Already present')\n",
    "                continue\n",
    "\n",
    "            bbox_lm = np.load(face_coordinates_directory + 'train/Positive/' + train_filelist[i] +'.npz')\n",
    "            bounding_boxes = bbox_lm['a']\n",
    "            if bounding_boxes.size == 0 or (bounding_boxes[0] == 0).all():\n",
    "                print(\"No bounding boxes for \" + train_filelist[i] + \". Adding empty file for the same\")\n",
    "                np.savez(processed_dataset_path + 'train/Positive/' + train_filelist[i], a = np.zeros(1), b = np.zeros(1))\n",
    "                continue\n",
    "            landmarks = bbox_lm['b']\n",
    "\n",
    "            for j in range(len(bounding_boxes)):\n",
    "                bbox_coordinates = bounding_boxes[j]\n",
    "                landmark = landmarks[j]\n",
    "                img_face = image.crop((bbox_coordinates[0], bbox_coordinates[1], bbox_coordinates[2], bbox_coordinates[3]))\n",
    "    \n",
    "                x = bbox_coordinates[0]\n",
    "                y = bbox_coordinates[1]\n",
    "            \n",
    "                for k in range(5):\n",
    "                    landmark[k] -= x\n",
    "                    landmark[k+5] -= y\n",
    "                img_face = np.array(img_face)\n",
    "                landmark = np.array(landmark)\n",
    "\n",
    "                if len(face_list) != 0:\n",
    "                    if img_face.shape[0] == face_list[-1].shape[0]:\n",
    "                        img_face = image.crop((bbox_coordinates[0] - 1, bbox_coordinates[1] - 1, bbox_coordinates[2], bbox_coordinates[3]))\n",
    "                        img_face = np.array(img_face)\n",
    "                        landmark += 1\n",
    "\n",
    "                face_list.append(img_face)\n",
    "                landmarks_new_coordinates.append(landmark)\n",
    "            face_list = np.asarray(face_list)\n",
    "            landmarks_new_coordinates = np.asarray(landmarks_new_coordinates)\n",
    "            np.savez(processed_dataset_path + 'train/Positive/' + train_filelist[i], a = face_list, b = landmarks_new_coordinates)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "    except:\n",
    "        print(\"Error/interrput at validation dataset file \" + val_filelist[i])\n",
    "        print(bounding_boxes)\n",
    "        print(landmarks)\n",
    "        print(bounding_boxes.shape)\n",
    "        print(landmarks.shape)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch0.4]",
   "language": "python",
   "name": "conda-env-pytorch0.4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
